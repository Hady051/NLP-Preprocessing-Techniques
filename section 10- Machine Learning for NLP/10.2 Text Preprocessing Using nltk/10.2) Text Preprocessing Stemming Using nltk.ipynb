{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stemming\n",
    "\n",
    "<u>**Stemming**</u> is the technique used to extract the base form of words by removing affixes from them.\n",
    "<u>**Stemming**</u> algorithms reduce words to their root or stem form.\n",
    "Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n"
   ],
   "id": "67edc42a1ac37232"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "## Examples:\n",
    "“chocolates”, “chocolatey”, “choco” to the root word -> “chocolate”\n",
    "“retrieval”, “retrieved”, “retrieves” reduced to the stem -> “retrieve”\n",
    "[eating, eat,eaten] --> eat, [going,gone,goes]---> go."
   ],
   "id": "fe1b4103069dbdf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Note:**\n",
    "It is important to note that **stemming** is different from **Lemmatization**. **Lemmatization** is the process of reducing a word to its base form, but unlike stemming, it takes into account <u>the context of the word</u>, and it <u>produces a valid word</u>, unlike **stemming** which may produce a <u>non-word as the root form</u>."
   ],
   "id": "e81ed2e5f975d3d"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "## Usages:\n",
    "# Classification Problem\n",
    "# Comments of product is a positive review or negative review\n",
    "# Reviews"
   ],
   "id": "8e626735b76c33bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:34.870119Z",
     "start_time": "2025-01-13T15:55:34.864797Z"
    }
   },
   "cell_type": "code",
   "source": "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]",
   "id": "310e5882dc9de1c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PorterStemmer",
   "id": "1756b1e200882e8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PorterStemmer is a stemming technique",
   "id": "84bd7fd9d051594e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.177716Z",
     "start_time": "2025-01-13T15:55:34.874112Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.stem import PorterStemmer",
   "id": "456c9e304eb8e5d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.394989Z",
     "start_time": "2025-01-13T15:55:36.390998Z"
    }
   },
   "cell_type": "code",
   "source": "porter_stemmer = PorterStemmer()",
   "id": "ccc479927197ad4c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.412568Z",
     "start_time": "2025-01-13T15:55:36.403168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word + \"-->\" + porter_stemmer.stem(word) )"
   ],
   "id": "fa52c7381765e033",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eaten\n",
      "writing-->write\n",
      "writes-->write\n",
      "programming-->program\n",
      "programs-->program\n",
      "history-->histori\n",
      "finally-->final\n",
      "finalized-->final\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.431129Z",
     "start_time": "2025-01-13T15:55:36.423519Z"
    }
   },
   "cell_type": "code",
   "source": "porter_stemmer.stem(\"congratulations\")",
   "id": "e614d0eee870bfef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "# // the meaning of some word changes which is a big disadvantage of stemming in some fields.",
   "id": "87cb7a9808d9d8f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.457598Z",
     "start_time": "2025-01-13T15:55:36.451534Z"
    }
   },
   "cell_type": "code",
   "source": "porter_stemmer.stem(\"sitting\")",
   "id": "a51b7ef35194af78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.480329Z",
     "start_time": "2025-01-13T15:55:36.477381Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b071b75e5f0e2454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "___",
   "id": "2fe300c0f8e0920f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ],
   "id": "e12f7b25ab1af62a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:36.492664Z",
     "start_time": "2025-01-13T15:55:36.488559Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.stem import RegexpStemmer",
   "id": "ab2398b0b58466a7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:55:37.060530Z",
     "start_time": "2025-01-13T15:55:36.508701Z"
    }
   },
   "cell_type": "code",
   "source": "# reg_exp_stemmer = RegexpStemmer()",
   "id": "94e92afc372775a2",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RegexpStemmer.__init__() missing 1 required positional argument: 'regexp'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m reg_exp_stemmer \u001B[38;5;241m=\u001B[39m \u001B[43mRegexpStemmer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: RegexpStemmer.__init__() missing 1 required positional argument: 'regexp'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:03.818214Z",
     "start_time": "2025-01-13T15:56:03.812923Z"
    }
   },
   "cell_type": "code",
   "source": "reg_exp_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)",
   "id": "cb02d13fec89ef84",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# // It has two arguments:\n",
    "\n",
    "1. 'regexp': The regular expression that should be used to identify morphological affixes.\n",
    "             they are accompanied by a $ sign. ex: ing$ or able$.\n",
    "\n",
    "2. min: The minimum length of string to stem"
   ],
   "id": "bad6fd90af3f46c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:05.708403Z",
     "start_time": "2025-01-13T15:56:05.702246Z"
    }
   },
   "cell_type": "code",
   "source": "reg_exp_stemmer.stem('eating')",
   "id": "85542711715d7b01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:09.365429Z",
     "start_time": "2025-01-13T15:56:09.359878Z"
    }
   },
   "cell_type": "code",
   "source": "reg_exp_stemmer.stem('ingesting')",
   "id": "d65735bfe82e77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingest'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:59:53.461803Z",
     "start_time": "2025-01-13T15:59:53.455703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word + \" --> \" + reg_exp_stemmer.stem(word) )"
   ],
   "id": "9dc2a8a5ed9b0a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating --> eat\n",
      "eats --> eat\n",
      "eaten --> eaten\n",
      "writing --> writ\n",
      "writes --> write\n",
      "programming --> programm\n",
      "programs --> program\n",
      "history --> history\n",
      "finally --> finally\n",
      "finalized --> finalized\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "___",
   "id": "369fa4b707c1fcf3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ],
   "id": "806a33e943791a1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:12.916715Z",
     "start_time": "2025-01-13T15:56:12.912730Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.stem import SnowballStemmer",
   "id": "416244a261e92a18",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:13.887974Z",
     "start_time": "2025-01-13T15:56:13.810836Z"
    }
   },
   "cell_type": "code",
   "source": "# snowball_stemmer = SnowballStemmer()",
   "id": "387758fb2ea8f2f7",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SnowballStemmer.__init__() missing 1 required positional argument: 'language'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m snowball_stemmer \u001B[38;5;241m=\u001B[39m \u001B[43mSnowballStemmer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: SnowballStemmer.__init__() missing 1 required positional argument: 'language'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "The following languages are supported: Arabic, Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish and Swedish.",
   "id": "d6bd8f3e55a4ac39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:19.006989Z",
     "start_time": "2025-01-13T15:56:18.767544Z"
    }
   },
   "cell_type": "code",
   "source": "# snowball_stemmer = SnowballStemmer(\"English\")",
   "id": "156e1806ef841d14",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The language 'English' is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m snowball_stemmer \u001B[38;5;241m=\u001B[39m \u001B[43mSnowballStemmer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEnglish\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\C coding projects\\Pycharm\\Generative AI-Udemy\\.venv\\Lib\\site-packages\\nltk\\stem\\snowball.py:106\u001B[0m, in \u001B[0;36mSnowballStemmer.__init__\u001B[1;34m(self, language, ignore_stopwords)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, language, ignore_stopwords\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m language \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlanguages:\n\u001B[1;32m--> 106\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe language \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlanguage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    107\u001B[0m     stemmerclass \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mglobals\u001B[39m()[language\u001B[38;5;241m.\u001B[39mcapitalize() \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStemmer\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstemmer \u001B[38;5;241m=\u001B[39m stemmerclass(ignore_stopwords)\n",
      "\u001B[1;31mValueError\u001B[0m: The language 'English' is not supported."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "# // language should be lowercase",
   "id": "1e0baf93d509cb1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:56:44.391657Z",
     "start_time": "2025-01-13T15:56:44.387995Z"
    }
   },
   "cell_type": "code",
   "source": "snowball_stemmer = SnowballStemmer('english')",
   "id": "7a9a6ade781c2ce7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:57:34.035279Z",
     "start_time": "2025-01-13T15:57:34.029756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word + \" --> \" + snowball_stemmer.stem(word) )"
   ],
   "id": "3da32cea6af1061d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating --> eat\n",
      "eats --> eat\n",
      "eaten --> eaten\n",
      "writing --> write\n",
      "writes --> write\n",
      "programming --> program\n",
      "programs --> program\n",
      "history --> histori\n",
      "finally --> final\n",
      "finalized --> final\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:04:30.343080Z",
     "start_time": "2025-01-13T16:04:30.337486Z"
    }
   },
   "cell_type": "code",
   "source": "porter_stemmer.stem(\"fairly\"), porter_stemmer.stem(\"sportingly\")",
   "id": "79b13ff3d07ecf07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:05:09.590101Z",
     "start_time": "2025-01-13T16:05:09.584785Z"
    }
   },
   "cell_type": "code",
   "source": "reg_exp_stemmer.stem(\"fairly\"), reg_exp_stemmer.stem(\"sportingly\")",
   "id": "3d23c6517fb3df37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:04:32.487340Z",
     "start_time": "2025-01-13T16:04:32.480295Z"
    }
   },
   "cell_type": "code",
   "source": "snowball_stemmer.stem(\"fairly\"), snowball_stemmer.stem(\"sportingly\")",
   "id": "8124bc9b8a54fe33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:07:46.983372Z",
     "start_time": "2025-01-13T16:07:46.979938Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "713958c0779ec20e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "___",
   "id": "2d8d4ef6016f822b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
